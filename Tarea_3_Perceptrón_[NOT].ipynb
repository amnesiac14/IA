{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9Gvt6wYoeca7pAX9ELHTu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amnesiac14/IA/blob/main/Tarea_3_Perceptr%C3%B3n_%5BNOT%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Entradas para el perceptron\n",
        "X = np.array([[1],\n",
        "              [0]]\n",
        "              )\n",
        "# Salidas\n",
        "Y = np.array([0, 1])\n",
        "# Pesos para las entradas\n",
        "weights = np.array([1.0])\n",
        "# Tasa de aprendizaje\n",
        "lr = 0.01\n",
        "# Epocas\n",
        "epochs = 100\n",
        "# Sesgo\n",
        "bias =  2.0"
      ],
      "metadata": {
        "id": "UwUH-C0vd7c1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El proceso de este ejemplo es análogo al caso OR, en el sentido del aprendizaje. Sin embargo, como vimos también en la tarea anterior, esta neurona toma los dos casos posibles de la tabla de verdad de una operación lógica NOT. Recordando que, para cada caso, solo tenemos una entrada, por ende, un solo peso en cada caso.\n",
        "Se realiza el proceso de reajuste la cantidad de épocas necesarias para cada uno de los casos de entrada de la operación NOT y obtenemos el peso y el sesgo óptimo que devuelve el resultado esperado en cada caso"
      ],
      "metadata": {
        "id": "px6FVXF6wuWX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3XT0m8_NdlAF"
      },
      "outputs": [],
      "source": [
        "class Perceptron:\n",
        "    def __init__(self, lr, epochs, weights, bias):\n",
        "        \"\"\"\n",
        "            Constructor del perceptron:\n",
        "            Guarda las variables\n",
        "            lr -> tasa de aprendizaje\n",
        "            epochs -> numero de epocas\n",
        "            weights -> vector de pesos iniciales\n",
        "            bias -> sesgo inicial\n",
        "        \"\"\"\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.weights = weights\n",
        "        self.bias = bias\n",
        "\n",
        "    def fit(self, X, Y):\n",
        "        \"\"\"\n",
        "            Realiza el entrenamiento del Perceptron.\n",
        "        \"\"\"\n",
        "        # Recorre el dataset la cantidad indicada en epocas\n",
        "        for epoch in range(self.epochs):\n",
        "            for j in range(X.shape[0]):\n",
        "                # Calcula la salida del perceptrón para la entrada actual\n",
        "                y_pred = self.activation_function(np.dot(self.weights, X[j]) + self.bias)\n",
        "                # Calcula el error\n",
        "                loss = Y[j] - y_pred\n",
        "                # Actualiza los pesos y el sesgo\n",
        "                self.weights += self.lr * loss * X[j]\n",
        "                self.bias += self.lr * loss\n",
        "            print(f\"Epoch {epoch}, Optimized Weights are {self.weights}, and bias is {self.bias}\")\n",
        "        # Imprime los valores finales de los parámetros aprendidos\n",
        "        print(f\"Optimized Weights are {self.weights} and bias is {self.bias}\")\n",
        "\n",
        "    def activation_function(self, activation):\n",
        "        \"\"\"\n",
        "            Función de activacion escalon\n",
        "        \"\"\"\n",
        "        return 1 if activation >= 0 else 0\n",
        "\n",
        "    def prediction(self, X):\n",
        "        \"\"\"\n",
        "            Calcula la salida del Perceptron para cada fila de entradas X.\n",
        "        \"\"\"\n",
        "        # Calcula producto punto + bias para todas las entradas\n",
        "        sum_ = np.dot(X, self.weights) + self.bias\n",
        "        # Mensaje input y su predicción\n",
        "        for i, s in enumerate(sum_):\n",
        "            print(f\"Input: {X[i]}, Predictions: {self.activation_function(sum_[i])}\")\n",
        "        # Devuelve un array con todas las predicciones\n",
        "        return np.array([self.activation_function(s) for s in sum_])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear una instancia del perceptrón\n",
        "p = Perceptron(lr=lr, epochs=epochs, weights=weights, bias=bias)\n",
        "# Entrenar el modelo\n",
        "p.fit(X, Y)\n",
        "# Usar el modelo entrenado para realizar predicciones\n",
        "predictions = p.prediction(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4ASvrpmd4C1",
        "outputId": "75af1eaf-973f-457b-e256-30c3ebcd78d6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Optimized Weights are [-0.01], and bias is 1.99\n",
            "Epoch 1, Optimized Weights are [-0.02], and bias is 1.98\n",
            "Epoch 2, Optimized Weights are [-0.03], and bias is 1.97\n",
            "Epoch 3, Optimized Weights are [-0.04], and bias is 1.96\n",
            "Epoch 4, Optimized Weights are [-0.05], and bias is 1.95\n",
            "Epoch 5, Optimized Weights are [-0.06], and bias is 1.94\n",
            "Epoch 6, Optimized Weights are [-0.07], and bias is 1.93\n",
            "Epoch 7, Optimized Weights are [-0.08], and bias is 1.92\n",
            "Epoch 8, Optimized Weights are [-0.09], and bias is 1.91\n",
            "Epoch 9, Optimized Weights are [-0.1], and bias is 1.9\n",
            "Epoch 10, Optimized Weights are [-0.11], and bias is 1.89\n",
            "Epoch 11, Optimized Weights are [-0.12], and bias is 1.88\n",
            "Epoch 12, Optimized Weights are [-0.13], and bias is 1.8699999999999999\n",
            "Epoch 13, Optimized Weights are [-0.14], and bias is 1.8599999999999999\n",
            "Epoch 14, Optimized Weights are [-0.15], and bias is 1.8499999999999999\n",
            "Epoch 15, Optimized Weights are [-0.16], and bias is 1.8399999999999999\n",
            "Epoch 16, Optimized Weights are [-0.17], and bias is 1.8299999999999998\n",
            "Epoch 17, Optimized Weights are [-0.18], and bias is 1.8199999999999998\n",
            "Epoch 18, Optimized Weights are [-0.19], and bias is 1.8099999999999998\n",
            "Epoch 19, Optimized Weights are [-0.2], and bias is 1.7999999999999998\n",
            "Epoch 20, Optimized Weights are [-0.21], and bias is 1.7899999999999998\n",
            "Epoch 21, Optimized Weights are [-0.22], and bias is 1.7799999999999998\n",
            "Epoch 22, Optimized Weights are [-0.23], and bias is 1.7699999999999998\n",
            "Epoch 23, Optimized Weights are [-0.24], and bias is 1.7599999999999998\n",
            "Epoch 24, Optimized Weights are [-0.25], and bias is 1.7499999999999998\n",
            "Epoch 25, Optimized Weights are [-0.26], and bias is 1.7399999999999998\n",
            "Epoch 26, Optimized Weights are [-0.27], and bias is 1.7299999999999998\n",
            "Epoch 27, Optimized Weights are [-0.28], and bias is 1.7199999999999998\n",
            "Epoch 28, Optimized Weights are [-0.29], and bias is 1.7099999999999997\n",
            "Epoch 29, Optimized Weights are [-0.3], and bias is 1.6999999999999997\n",
            "Epoch 30, Optimized Weights are [-0.31], and bias is 1.6899999999999997\n",
            "Epoch 31, Optimized Weights are [-0.32], and bias is 1.6799999999999997\n",
            "Epoch 32, Optimized Weights are [-0.33], and bias is 1.6699999999999997\n",
            "Epoch 33, Optimized Weights are [-0.34], and bias is 1.6599999999999997\n",
            "Epoch 34, Optimized Weights are [-0.35], and bias is 1.6499999999999997\n",
            "Epoch 35, Optimized Weights are [-0.36], and bias is 1.6399999999999997\n",
            "Epoch 36, Optimized Weights are [-0.37], and bias is 1.6299999999999997\n",
            "Epoch 37, Optimized Weights are [-0.38], and bias is 1.6199999999999997\n",
            "Epoch 38, Optimized Weights are [-0.39], and bias is 1.6099999999999997\n",
            "Epoch 39, Optimized Weights are [-0.4], and bias is 1.5999999999999996\n",
            "Epoch 40, Optimized Weights are [-0.41], and bias is 1.5899999999999996\n",
            "Epoch 41, Optimized Weights are [-0.42], and bias is 1.5799999999999996\n",
            "Epoch 42, Optimized Weights are [-0.43], and bias is 1.5699999999999996\n",
            "Epoch 43, Optimized Weights are [-0.44], and bias is 1.5599999999999996\n",
            "Epoch 44, Optimized Weights are [-0.45], and bias is 1.5499999999999996\n",
            "Epoch 45, Optimized Weights are [-0.46], and bias is 1.5399999999999996\n",
            "Epoch 46, Optimized Weights are [-0.47], and bias is 1.5299999999999996\n",
            "Epoch 47, Optimized Weights are [-0.48], and bias is 1.5199999999999996\n",
            "Epoch 48, Optimized Weights are [-0.49], and bias is 1.5099999999999996\n",
            "Epoch 49, Optimized Weights are [-0.5], and bias is 1.4999999999999996\n",
            "Epoch 50, Optimized Weights are [-0.51], and bias is 1.4899999999999995\n",
            "Epoch 51, Optimized Weights are [-0.52], and bias is 1.4799999999999995\n",
            "Epoch 52, Optimized Weights are [-0.53], and bias is 1.4699999999999995\n",
            "Epoch 53, Optimized Weights are [-0.54], and bias is 1.4599999999999995\n",
            "Epoch 54, Optimized Weights are [-0.55], and bias is 1.4499999999999995\n",
            "Epoch 55, Optimized Weights are [-0.56], and bias is 1.4399999999999995\n",
            "Epoch 56, Optimized Weights are [-0.57], and bias is 1.4299999999999995\n",
            "Epoch 57, Optimized Weights are [-0.58], and bias is 1.4199999999999995\n",
            "Epoch 58, Optimized Weights are [-0.59], and bias is 1.4099999999999995\n",
            "Epoch 59, Optimized Weights are [-0.6], and bias is 1.3999999999999995\n",
            "Epoch 60, Optimized Weights are [-0.61], and bias is 1.3899999999999995\n",
            "Epoch 61, Optimized Weights are [-0.62], and bias is 1.3799999999999994\n",
            "Epoch 62, Optimized Weights are [-0.63], and bias is 1.3699999999999994\n",
            "Epoch 63, Optimized Weights are [-0.64], and bias is 1.3599999999999994\n",
            "Epoch 64, Optimized Weights are [-0.65], and bias is 1.3499999999999994\n",
            "Epoch 65, Optimized Weights are [-0.66], and bias is 1.3399999999999994\n",
            "Epoch 66, Optimized Weights are [-0.67], and bias is 1.3299999999999994\n",
            "Epoch 67, Optimized Weights are [-0.68], and bias is 1.3199999999999994\n",
            "Epoch 68, Optimized Weights are [-0.69], and bias is 1.3099999999999994\n",
            "Epoch 69, Optimized Weights are [-0.7], and bias is 1.2999999999999994\n",
            "Epoch 70, Optimized Weights are [-0.71], and bias is 1.2899999999999994\n",
            "Epoch 71, Optimized Weights are [-0.72], and bias is 1.2799999999999994\n",
            "Epoch 72, Optimized Weights are [-0.73], and bias is 1.2699999999999994\n",
            "Epoch 73, Optimized Weights are [-0.74], and bias is 1.2599999999999993\n",
            "Epoch 74, Optimized Weights are [-0.75], and bias is 1.2499999999999993\n",
            "Epoch 75, Optimized Weights are [-0.76], and bias is 1.2399999999999993\n",
            "Epoch 76, Optimized Weights are [-0.77], and bias is 1.2299999999999993\n",
            "Epoch 77, Optimized Weights are [-0.78], and bias is 1.2199999999999993\n",
            "Epoch 78, Optimized Weights are [-0.79], and bias is 1.2099999999999993\n",
            "Epoch 79, Optimized Weights are [-0.8], and bias is 1.1999999999999993\n",
            "Epoch 80, Optimized Weights are [-0.81], and bias is 1.1899999999999993\n",
            "Epoch 81, Optimized Weights are [-0.82], and bias is 1.1799999999999993\n",
            "Epoch 82, Optimized Weights are [-0.83], and bias is 1.1699999999999993\n",
            "Epoch 83, Optimized Weights are [-0.84], and bias is 1.1599999999999993\n",
            "Epoch 84, Optimized Weights are [-0.85], and bias is 1.1499999999999992\n",
            "Epoch 85, Optimized Weights are [-0.86], and bias is 1.1399999999999992\n",
            "Epoch 86, Optimized Weights are [-0.87], and bias is 1.1299999999999992\n",
            "Epoch 87, Optimized Weights are [-0.88], and bias is 1.1199999999999992\n",
            "Epoch 88, Optimized Weights are [-0.89], and bias is 1.1099999999999992\n",
            "Epoch 89, Optimized Weights are [-0.9], and bias is 1.0999999999999992\n",
            "Epoch 90, Optimized Weights are [-0.91], and bias is 1.0899999999999992\n",
            "Epoch 91, Optimized Weights are [-0.92], and bias is 1.0799999999999992\n",
            "Epoch 92, Optimized Weights are [-0.93], and bias is 1.0699999999999992\n",
            "Epoch 93, Optimized Weights are [-0.94], and bias is 1.0599999999999992\n",
            "Epoch 94, Optimized Weights are [-0.95], and bias is 1.0499999999999992\n",
            "Epoch 95, Optimized Weights are [-0.96], and bias is 1.0399999999999991\n",
            "Epoch 96, Optimized Weights are [-0.97], and bias is 1.0299999999999991\n",
            "Epoch 97, Optimized Weights are [-0.98], and bias is 1.0199999999999991\n",
            "Epoch 98, Optimized Weights are [-0.99], and bias is 1.0099999999999991\n",
            "Epoch 99, Optimized Weights are [-1.], and bias is 0.9999999999999991\n",
            "Optimized Weights are [-1.] and bias is 0.9999999999999991\n",
            "Input: [1], Predictions: 0\n",
            "Input: [0], Predictions: 1\n"
          ]
        }
      ]
    }
  ]
}